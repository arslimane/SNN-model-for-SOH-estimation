{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import struct\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pynvml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxI,minI,maxV,minV,maxT,minT=[9.381874,-20.00478,3.600254,1.989369,57.09709,18.68196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequence_Split_SOC(df,X,Y):\n",
    "    for i in range(0,500):\n",
    "        for j in range(0,len(df[\"SOC\"][i])-100):\n",
    "            I=df[\"I[A]\"][i][j:j+100]\n",
    "            V=df[\"U[V]\"][i][j:j+100]\n",
    "            T=df[\"T1[°C]\"][i][j:j+100]\n",
    "            if(len(I)==100):\n",
    "                Y.append(df[\"SOC\"][i][j+100])\n",
    "                X.append([I,V,T])\n",
    "\n",
    "\n",
    "def Sequence_Split_SOH(sequence,X,y,step_in,step_out):\n",
    "\n",
    "   for i in range(len(sequence)):\n",
    "       end_ix = i + step_in\n",
    "       out_end_ix = end_ix + step_out\n",
    "\n",
    "       if out_end_ix > len(sequence):\n",
    "              break\n",
    " # gather input and output parts of the pattern\n",
    "       seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "       X.append(seq_x.drop([\"SOC\",\"SOH\",\"Qd\",\"QC\",\"Time[h]\",\"Cycle_index\"],axis=1).to_numpy())\n",
    "       y.append(seq_y[\"SOH\"].to_numpy())\n",
    "   return X, y\n",
    "\n",
    "def Normalization(data,stepin,maxlength=1500):\n",
    "    nd=[]\n",
    "    for i in range(len(data)):\n",
    "        im=[]\n",
    "        vm=[]\n",
    "        tm=[]\n",
    "        for c in range(len(data[i])):\n",
    "            norm_i = (data[i][c][0] - minI) / (maxI - minI)\n",
    "            norm_v = (data[i][c][1] - minV) / (maxV - minV)\n",
    "            norm_t = (data[i][c][2] - minT) / (maxT - minT)\n",
    "            t=np.zeros((1500,))\n",
    "            t[0:min(1500,len(norm_v))]=norm_i[:min(1500,len(norm_i))]\n",
    "            im.append(t)\n",
    "\n",
    "            t=np.zeros((1500,))\n",
    "            t[0:min(1500,len(norm_v))]=norm_v[:min(1500,len(norm_v))]\n",
    "            vm.append(t)\n",
    "\n",
    "            t=np.zeros((1500,))\n",
    "            t[0:min(1500,len(norm_v))]=norm_t[:min(1500,len(norm_t))]\n",
    "            tm.append(t)\n",
    "        d=np.float32([im,vm,tm])\n",
    "        d=np.reshape(np.transpose(np.reshape(d,(3,stepin*1500))),(1500*stepin,3))\n",
    "        nd.append(d)\n",
    "    return nd\n",
    "def Encoding(data,stpsin):\n",
    "    nd= []\n",
    "    r=(stpsin*1500)-1\n",
    "    for i in range(len(data)):\n",
    "        current = torch.tensor(data[i], dtype=torch.float32, device=\"cuda\")  \n",
    "        dffi = torch.abs(torch.diff(current[:,0]))\n",
    "        dffv = torch.abs(torch.diff(current[:,1]))\n",
    "        dfft = torch.abs(torch.diff(current[:,2]))\n",
    "        im_seq = (dffi >= 0.0002).int()\n",
    "        vm_seq = (dffv >= 0.0002).int()\n",
    "        tm_seq = (dfft >= 0.002).int()\n",
    "        d=np.float32([im_seq.detach().cpu().numpy(),vm_seq.detach().cpu().numpy(),tm_seq.detach().cpu().numpy()])\n",
    "        d=np.reshape(np.transpose(np.reshape(d,(3,r))),(r,3))\n",
    "        nd.append(d)\n",
    "    return nd\n",
    "\n",
    "loss2=nn.MSELoss()\n",
    "loss=nn.L1Loss()\n",
    "def measure_accuracy(model, dataloader):\n",
    "  t=[]\n",
    "  with torch.no_grad():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for data, targets in iter(dataloader):\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # forward-pass\n",
    "      t1=time.time()\n",
    "      spk_rec= model(data)\n",
    "      t2=time.time()\n",
    "      t.append(t2-t1)\n",
    "      loss_mae= torch.zeros((1), dtype=dtype, device=device)\n",
    "      loss_mse= torch.zeros((1), dtype=dtype, device=device)\n",
    "      loss_rmse= torch.zeros((1), dtype=dtype, device=device)\n",
    "      loss_mae = loss(spk_rec, targets)\n",
    "      loss_mse=loss2(spk_rec, targets) \n",
    "      loss_rmse=torch.sqrt(loss_mse)\n",
    "    return loss_mae,loss_mse,loss_rmse,np.average(t)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.shape)\n",
    "\n",
    "class GRU_CNN(nn.Module):\n",
    "    def __init__(self,stepin,stpout):\n",
    "        super(GRU_CNN, self).__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            Reshape((3, stepin*1500)),  # From (batch, 37500, 3) ➜ (batch, 3, 37500)\n",
    "\n",
    "            nn.Conv1d(3, 64, kernel_size=32, padding='same'),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "\n",
    "          \n",
    "            nn.AdaptiveAvgPool1d(4)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(64 * 4, 64)  \n",
    "\n",
    "        self.gru = nn.GRU(3, 256, batch_first=True)\n",
    "        self.dense2 = nn.Linear(256, 64)\n",
    "\n",
    "        self.concat = nn.Linear(128, stpout)  \n",
    "\n",
    "    def forward(self, input_stream):\n",
    "        x1 = self.conv_block(input_stream)\n",
    "        x1 = self.flatten(x1)\n",
    "        x1 = self.dense1(x1)\n",
    "        _, x2 = self.gru(input_stream)\n",
    "        x2 = x2.squeeze(0)\n",
    "        x2 = self.dense2(x2)\n",
    "\n",
    "        combined = torch.cat((x1, x2), dim=1)\n",
    "        output = self.concat(combined)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Model(Steps_in,Steps_out):\n",
    "    \n",
    "    for stpsin,stpout in tqdm(zip(Steps_in,Steps_out)):\n",
    "\n",
    "        data = np.load(f\"Data\\\\Xtrain_normilized_{stpsin}_{stpout}.npz\")\n",
    "        X1 = data['Data']\n",
    "        data = np.load(f\"Data\\\\Ytrain_{stpsin}_{stpout}.npz\")\n",
    "        Y1 = data['y']\n",
    "        print(f\"Trainning will be on {device}\")\n",
    "\n",
    "\n",
    "        X = np.float32(X1)\n",
    "        Y= np.float32(Y1)\n",
    "        Y=np.reshape(Y,(len(Y),stpout))\n",
    "\n",
    "        x_tensor = torch.tensor(X)\n",
    "        y_tensor = torch.tensor(Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "        batch_size = 32  \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        model = GRU_CNN(stpsin,stpout).to(device)\n",
    "        #summary(model, input_size=(1500*stpsin, 3)) \n",
    "        data = np.load(f\"Data\\\\Xtest_normilized_{stpsin}_{stpout}.npz\")\n",
    "        X2 = data['Data']\n",
    "        data = np.load(f\"Data\\\\Ytest_{stpsin}_{stpout}.npz\")\n",
    "        Y2 = data['y']\n",
    "        X = np.float32(X2)\n",
    "        Y= np.float32(Y2)\n",
    "        Y=np.reshape(Y,(len(Y),stpout))\n",
    "\n",
    "        x_tensor = torch.tensor(X)\n",
    "        y_tensor = torch.tensor(Y)\n",
    "\n",
    "        dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "\n",
    "        batch_size = 64  \n",
    "        test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        num_epochs = 1\n",
    "        loss_hist = []\n",
    "        test_loss_hist = []\n",
    "        counter = 0\n",
    "        loss = nn.L1Loss()\n",
    "        num_steps=1\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "        # Outer training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            iter_counter = 0\n",
    "            train_batch = iter(train_loader)\n",
    "            # Minibatch training loop\n",
    "            for data, targets in train_batch:\n",
    "                data = data.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                model.train()\n",
    "                spk_rec = model(data)\n",
    "\n",
    "                # initialize the loss & sum over time\n",
    "                loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "                for step in range(num_steps):\n",
    "                    loss_val += loss(spk_rec, targets)\n",
    "\n",
    "                # Gradient calculation + weight update\n",
    "                optimizer.zero_grad()\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Store loss history for future plotting\n",
    "                loss_hist.append(loss_val.item())\n",
    "\n",
    "                # Test set\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    test_data, test_targets = next(iter(test_loader))\n",
    "                    test_data = test_data.to(device)\n",
    "                    test_targets = test_targets.to(device)\n",
    "\n",
    "                    # Test set forward pass\n",
    "                    test_spk= model(test_data)\n",
    "\n",
    "                    # Test set loss\n",
    "                    test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "                    for step in range(num_steps):\n",
    "                        test_loss += loss(test_spk, test_targets)\n",
    "                    test_loss_hist.append(test_loss.item())\n",
    "                    counter += 1\n",
    "                    iter_counter +=1\n",
    "\n",
    "\n",
    "        torch.save(model.state_dict(), f'Models\\\\modelGRU_weights_{stpsin}_{stpout}.pth')\n",
    "        loss_mae,loss_mse,loss_rmse,tttime=measure_accuracy(model, test_loader)\n",
    "        input = torch.randn(1, 1500*stpsin, 3).to('cuda')\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        start = time.time()\n",
    "        power_start = pynvml.nvmlDeviceGetPowerUsage(handle)  # in mW\n",
    "\n",
    "        # Run your inference\n",
    "        output = model(input)\n",
    "\n",
    "        power_end = pynvml.nvmlDeviceGetPowerUsage(handle)\n",
    "        end = time.time()\n",
    "\n",
    "        avg_power = (power_start + power_end) / 2  # in milliwatts\n",
    "        duration = end - start  # in seconds\n",
    "\n",
    "        energy_mJ = avg_power * duration  # mJ = mW * s\n",
    "\n",
    "        print(\"MAE\",loss_mae,\"MSE\",loss_mse,\"RMSE\",loss_rmse,\"RunningTime\",np.mean(tttime),\"Energy\",energy_mJ) \n",
    "\n",
    "        results=[loss_mae.item(),loss_mse.item(),loss_rmse.item(),tttime,energy_mJ]\n",
    "        np.save(f\"Results\\\\resultsGRU_{stpsin}_{stpout}\",results)\n",
    "\n",
    "        del model, optimizer, train_loader, test_loader\n",
    "        del X, Y, X1, X2, Y1, Y2, x_tensor, y_tensor\n",
    "        del dataset, data, targets, spk_rec\n",
    "        del test_spk, test_data, test_targets\n",
    "        del loss_val, test_loss, loss_hist, test_loss_hist\n",
    "        \n",
    "        # Free CUDA memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        # Free CPU memory\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning will be on cuda\n",
      "MAE tensor(0.1696, device='cuda:0') MSE tensor(0.0370, device='cuda:0') RMSE tensor(0.1925, device='cuda:0') RunningTime 1.8454160196287137 Energy 25764.207315444946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [31:58, 1918.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning will be on cuda\n",
      "MAE tensor(0.1053, device='cuda:0') MSE tensor(0.0169, device='cuda:0') RMSE tensor(0.1301, device='cuda:0') RunningTime 2.6645817214792427 Energy 28234.775030612946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [2:04:46, 4065.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning will be on cuda\n",
      "MAE tensor(0.0771, device='cuda:0') MSE tensor(0.0108, device='cuda:0') RMSE tensor(0.1039, device='cuda:0') RunningTime 2.7781561339667085 Energy 39127.95166039467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [2:46:10, 3343.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning will be on cuda\n",
      "MAE tensor(0.1117, device='cuda:0') MSE tensor(0.0233, device='cuda:0') RMSE tensor(0.1527, device='cuda:0') RunningTime 2.8004946040215892 Energy 34557.29510319233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [3:26:40, 2982.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning will be on cuda\n",
      "MAE tensor(0.0678, device='cuda:0') MSE tensor(0.0097, device='cuda:0') RMSE tensor(0.0984, device='cuda:0') RunningTime 2.925456549607071 Energy 32044.75672507286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [4:06:07, 2953.43s/it]\n"
     ]
    }
   ],
   "source": [
    "Steps_in=[1,10,20,25,25,25,25]\n",
    "Steps_out=[1,5,10,25,50,100,200]\n",
    "\n",
    "Test_Model(Steps_in,Steps_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
